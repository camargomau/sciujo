---
date: 2024-04-04
type: ðŸ§ 
tags:
  - MAC/6/PE
---

**Topics:** [[Markov Chain]] - [[Stationary Process]] - [[Stationary Transition Probability]]

---

_**(definition)**_

A **finite and stationary [[Markov Chain|Markov chain]]** is a Markov chain with a finite [[State Set|state set]] whose transition probabilities are [[Stationary Transition Probability|stationary]].

A given finite and stationary Markov chain can be characterised by:

1. Its finite state set
2. Its one step [[Transition Matrix|transition matrix]]
3. Its [[Initial Probability Vector|initial probability vector]]
