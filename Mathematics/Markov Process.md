---
date: 2024-04-03
type: ðŸ§ 
tags:
  - MAC/6/PE
---

**Topics:** [[Types of Stochastic Processes]]

---

_**(definition)**_

A **Markov process** is a [[Stochastic Process|stochastic process]] where we know the present state of the system, but the past states _don't_ influence the future states of the system ([[Markov Property|Markov property]]). However, the present state _can_ influence the _immediate_ future state of the system.

> [!example]-
> Each day, we determine the mood of a person (happy, sad, indifferent, etc.). Today's mood is defined according to the yesterday's.

We'll have, then, variables that are conditional to the _immediate_ previous state.
