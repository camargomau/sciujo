---
date: 2024-04-04
type: ðŸ§ 
tags:
  - MAC/6/PE
---

**Topics:** [[Transition Probabilities in a Markov Chain]] - [[Markov Chain]]

---

_**(definition)**_

In a [[Markov Chain|Markov chain]] $\left\{ X_{t} \mid t \in \mathbb{N} \right\}$, a **one step [[Transition Probabilities in a Markov Chain|transition probability]]** is a probability of the form:

$$
\mathbb{P}(X_{t+1}=j \mid X_{t}=i)
$$

â€¦where $i, j$ are any two possible states of the chain.
