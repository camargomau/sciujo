---
date: 2024-04-04
type: ðŸ§ 
tags:
  - MAC/6/PE
---

**Topics:** [[Types of Stochastic Processes]]

---

_**(definition)**_

A **Markov chain** is a [[Chain|chain]] that satisfies the [[Markov Property|Markov property]]. 

In Markov chains, [[Transition Probabilities in a Markov Chain|the study of transition probabilities]] is of special interest.
