---
date: 2024-04-04
type: ðŸ§ 
tags:
  - MAC/6/PE
---

**Topics:** [[Markov Chain]] - [[Ergodic Markov Chain]]

---

_**(definition)**_

A **regular Markov chain** is an [[Ergodic Markov Chain|ergodic Markov chain]] that is not [[Cyclical Markov Chain|cyclical]].

In a regular Markov chains, the probability of reaching a given state is constant when the number of steps is high enough, regardless of the initial state. As such, regular Markov chains are characterised by a [[Steady State Probability|stationary distribution (vector)]], which contains these constant steady state probabilities. 